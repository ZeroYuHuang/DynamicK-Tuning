{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the activation of the Llama model and its K-Neuron variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "from topk_models import TopKLlamaForCausalLM, TopKLlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Configurations of this notobook\n",
    "MODEL_PATH = 'models/Llama-2-7b-hf'\n",
    "MODEL_TYPE = 'original'\n",
    "DATA_PATH = './data/alpaca/'\n",
    "N_SAMPLES = 20\n",
    "if MODEL_TYPE == 'original':\n",
    "    model = LlamaForCausalLM.from_pretrained(\"./models/Llama-2-7b-hf/\", device_map=\"auto\")\n",
    "else:\n",
    "    config = TopKLlamaConfig.from_json_file('7b_base_configs.json')\n",
    "    model = TopKLlamaForCausalLM.from_pretrained(\n",
    "        \"./models/Llama-2-7b-hf/\", \n",
    "        device_map=\"auto\",\n",
    "        config=config\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./models/Llama-2-7b-hf/\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample some data points from the instruction-tuning data, e.g., Alpaca52K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(DATA_PATH)['train']\n",
    "data_idx_sample = random.sample([_ for _ in range(len(data))], N_SAMPLES)\n",
    "data_samples = [data[i] for i in data_idx_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the forwardhook for recording activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 32\n",
    "hidden_inp = {\n",
    "    \"gate_proj\": [[] for _ in range(n_layer)], \"up_proj\": [[] for _ in range(n_layer)], \"down_proj\": [[] for _ in range(n_layer)]\n",
    "}\n",
    "hidden_out = {\n",
    "    \"gate_proj\": [[] for _ in range(n_layer)], \"up_proj\": [[] for _ in range(n_layer)], \"down_proj\": [[] for _ in range(n_layer)]\n",
    "}\n",
    "\n",
    "def forward_input_hook(name, layer_id):\n",
    "    def fn(module: nn.Module, inp, out):\n",
    "        hidden_inp[name][layer_id].append(inp)\n",
    "    return fn\n",
    "\n",
    "def forward_output_hook(name, layer_id):\n",
    "    def fn(module: nn.Module, input, output):\n",
    "        hidden_out[name][layer_id].append(inp)\n",
    "    return fn\n",
    "            \n",
    "for n, m in model.named_modules():\n",
    "    if len(n.split(\".\")) < 5:\n",
    "        continue\n",
    "    layer_id = int(n.split(\".\")[2])\n",
    "    name = n.split(\".\")[-1]\n",
    "    if \"LlamaMLP\" in n.split(\".\"):\n",
    "        m.register_forward_hook(forward_input_hook(name, layer_id))\n",
    "        m.register_forward_hook(forward_output_hook(name, layer_id)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(data_samples):\n",
    "    inp = prompt.format_map(d)\n",
    "    out = f\"{d['output']}{tokenizer.eos_token}\"\n",
    "    text = inp + out\n",
    "    # tokenize\n",
    "    input_ids = tokenizer(text, return_tensors='pt').input_ids # .to(device)\n",
    "    # forward\n",
    "    y = model(input_ids[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Q1: how many neurons are activated by an activation value that is larger than T?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb 单元格 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.96.164.59/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m T \u001b[39min\u001b[39;00m T_lists:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.96.164.59/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     gate_act_rate \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.96.164.59/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_layer):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.96.164.59/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         after_act \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msilu(gate_h[i][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.96.164.59/home/hkustadmin/huangzeyu/DynamicK-Tuning/analysis_activation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         gate_act_rate\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mabs(after_act) \u001b[39m>\u001b[39m T) \u001b[39m/\u001b[39m tot)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_layer' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAFlCAYAAABrxYI/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUElEQVR4nO3df2zc5X0H8I/t4DOo2IRlcX7MNIOO0hZIaEI8QxGi8moJlC5/TPWgSrKIH6PNEI21lYRAXEobZwxQpBIakcLoH2VJiwBVTWTKvEYVxVPUJJboSEA00GRVbZJ12FlobWJ/90eEXTfnJOfEj+3j9ZLuD3/7PHfPB7vv6O0735VkWZYFAAAAMKZKx/sAAAAA8GGggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgUX8J/+9KexaNGimDVrVpSUlMQLL7xwyj07duyIT3/605HL5eJjH/tYPP3006M4KsDEJh8B8pOPAMcVXMCPHj0ac+fOjY0bN57W+rfeeituuummuOGGG6KjoyO+8pWvxG233RYvvvhiwYcFmMjkI0B+8hHguJIsy7JRby4pieeffz4WL1484pp77rkntm3bFr/4xS8Gr/3t3/5tvPvuu9Ha2jrahwaY0OQjQH7yEfgwmzLWD9De3h719fXDrjU0NMRXvvKVEff09vZGb2/v4NcDAwPx29/+Nv7kT/4kSkpKxuqoQJHKsiyOHDkSs2bNitLSifPWF/IRGG/yEWBkY5GRY17AOzs7o7q6eti16urq6Onpid/97ndx7rnnnrCnpaUlHnjggbE+GvAhc/DgwfizP/uz8T7GIPkITBTyEWBkZzMjx7yAj8bq1aujqalp8Ovu7u646KKL4uDBg1FZWTmOJwMmo56enqipqYnzzz9/vI9yxuQjcDbJR4CRjUVGjnkBnzFjRnR1dQ271tXVFZWVlXl/exkRkcvlIpfLnXC9srJSgAKjNtFegigfgYlCPgKM7Gxm5Jj/sU9dXV20tbUNu/bSSy9FXV3dWD80wIQmHwHyk49AsSq4gP/f//1fdHR0REdHR0Qc/5iIjo6OOHDgQEQcf/nP0qVLB9ffeeedsX///vjqV78a+/bti8cffzy+//3vx8qVK8/OBAAThHwEyE8+AhxXcAH/+c9/HldddVVcddVVERHR1NQUV111VaxduzYiIn7zm98MhmlExJ//+Z/Htm3b4qWXXoq5c+fGI488Et/5zneioaHhLI0AMDHIR4D85CPAcWf0OeCp9PT0RFVVVXR3d/sbHqBgxZwhxTwbMPaKOUOKeTYgjbHIkYnzgY8AAABQxBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgARGVcA3btwYc+bMiYqKiqitrY2dO3eedP2GDRvi4x//eJx77rlRU1MTK1eujN///vejOjDARCYfAfKTjwCjKOBbt26NpqamaG5ujt27d8fcuXOjoaEh3nnnnbzrn3nmmVi1alU0NzfH3r1748knn4ytW7fGvffee8aHB5hI5CNAfvIR4LiCC/ijjz4at99+eyxfvjw++clPxqZNm+K8886Lp556Ku/6V155Ja699tq45ZZbYs6cOfG5z30ubr755lP+1hNgspGPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29rx7rrnmmti1a9dgYO7fvz+2b98eN95444iP09vbGz09PcNuABOZfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/bty7vnlltuicOHD8dnPvOZyLIsjh07FnfeeedJX0LU0tISDzzwQCFHAxhX8hEgP/kIMGTM3wV9x44dsW7dunj88cdj9+7d8dxzz8W2bdviwQcfHHHP6tWro7u7e/B28ODBsT4mQHLyESA/+QgUq4KeAZ82bVqUlZVFV1fXsOtdXV0xY8aMvHvuv//+WLJkSdx2220REXHFFVfE0aNH44477og1a9ZEaemJvwPI5XKRy+UKORrAuJKPAPnJR4AhBT0DXl5eHvPnz4+2trbBawMDA9HW1hZ1dXV597z33nsnhGRZWVlERGRZVuh5ASYk+QiQn3wEGFLQM+AREU1NTbFs2bJYsGBBLFy4MDZs2BBHjx6N5cuXR0TE0qVLY/bs2dHS0hIREYsWLYpHH300rrrqqqitrY0333wz7r///li0aNFgkAIUA/kIkJ98BDiu4ALe2NgYhw4dirVr10ZnZ2fMmzcvWltbB99Y48CBA8N+Y3nfffdFSUlJ3HffffHrX/86/vRP/zQWLVoU3/zmN8/eFAATgHwEyE8+AhxXkk2C1/H09PREVVVVdHd3R2Vl5XgfB5hkijlDink2YOwVc4YU82xAGmORI2P+LugAAACAAg4AAABJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPOn6d999N1asWBEzZ86MXC4Xl156aWzfvn1UBwaYyOQjQH7yESBiSqEbtm7dGk1NTbFp06aora2NDRs2RENDQ7z++usxffr0E9b39fXFX/3VX8X06dPj2WefjdmzZ8evfvWruOCCC87G+QEmDPkIkJ98BDiuJMuyrJANtbW1cfXVV8djjz0WEREDAwNRU1MTd911V6xateqE9Zs2bYp/+Zd/iX379sU555wzqkP29PREVVVVdHd3R2Vl5ajuA/jwSpUh8hGYbOQjwMjGIkcKegl6X19f7Nq1K+rr64fuoLQ06uvro729Pe+eH/7wh1FXVxcrVqyI6urquPzyy2PdunXR398/4uP09vZGT0/PsBvARCYfAfKTjwBDCirghw8fjv7+/qiurh52vbq6Ojo7O/Pu2b9/fzz77LPR398f27dvj/vvvz8eeeSR+MY3vjHi47S0tERVVdXgraamppBjAiQnHwHyk48AQ8b8XdAHBgZi+vTp8cQTT8T8+fOjsbEx1qxZE5s2bRpxz+rVq6O7u3vwdvDgwbE+JkBy8hEgP/kIFKuC3oRt2rRpUVZWFl1dXcOud3V1xYwZM/LumTlzZpxzzjlRVlY2eO0Tn/hEdHZ2Rl9fX5SXl5+wJ5fLRS6XK+RoAONKPgLkJx8BhhT0DHh5eXnMnz8/2traBq8NDAxEW1tb1NXV5d1z7bXXxptvvhkDAwOD1954442YOXNm3vAEmIzkI0B+8hFgSMEvQW9qaorNmzfHd7/73di7d2986UtfiqNHj8by5csjImLp0qWxevXqwfVf+tKX4re//W3cfffd8cYbb8S2bdti3bp1sWLFirM3BcAEIB8B8pOPAMcV/DngjY2NcejQoVi7dm10dnbGvHnzorW1dfCNNQ4cOBClpUO9vqamJl588cVYuXJlXHnllTF79uy4++6745577jl7UwBMAPIRID/5CHBcwZ8DPh58jiNwJoo5Q4p5NmDsFXOGFPNsQBrj/jngAAAAwOgo4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPK19W7ZsiZKSkli8ePFoHhZgwpOPAPnJR4BRFPCtW7dGU1NTNDc3x+7du2Pu3LnR0NAQ77zzzkn3vf322/GP//iPcd111436sAATmXwEyE8+AhxXcAF/9NFH4/bbb4/ly5fHJz/5ydi0aVOcd9558dRTT424p7+/P774xS/GAw88EBdffPEZHRhgopKPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29hH3ff3rX4/p06fHrbfeelqP09vbGz09PcNuABOZfATITz4CDCmogB8+fDj6+/ujurp62PXq6uro7OzMu+fll1+OJ598MjZv3nzaj9PS0hJVVVWDt5qamkKOCZCcfATITz4CDBnTd0E/cuRILFmyJDZv3hzTpk077X2rV6+O7u7uwdvBgwfH8JQA6clHgPzkI1DMphSyeNq0aVFWVhZdXV3Drnd1dcWMGTNOWP/LX/4y3n777Vi0aNHgtYGBgeMPPGVKvP7663HJJZecsC+Xy0UulyvkaADjSj4C5CcfAYYU9Ax4eXl5zJ8/P9ra2gavDQwMRFtbW9TV1Z2w/rLLLotXX301Ojo6Bm+f//zn44YbboiOjg4vDQKKhnwEyE8+Agwp6BnwiIimpqZYtmxZLFiwIBYuXBgbNmyIo0ePxvLlyyMiYunSpTF79uxoaWmJioqKuPzyy4ftv+CCCyIiTrgOMNnJR4D85CPAcQUX8MbGxjh06FCsXbs2Ojs7Y968edHa2jr4xhoHDhyI0tIx/dNygAlJPgLkJx8BjivJsiwb70OcSk9PT1RVVUV3d3dUVlaO93GASaaYM6SYZwPGXjFnSDHPBqQxFjniV40AAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACYyqgG/cuDHmzJkTFRUVUVtbGzt37hxx7ebNm+O6666LqVOnxtSpU6O+vv6k6wEmM/kIkJ98BBhFAd+6dWs0NTVFc3Nz7N69O+bOnRsNDQ3xzjvv5F2/Y8eOuPnmm+MnP/lJtLe3R01NTXzuc5+LX//612d8eICJRD4C5CcfAY4rybIsK2RDbW1tXH311fHYY49FRMTAwEDU1NTEXXfdFatWrTrl/v7+/pg6dWo89thjsXTp0tN6zJ6enqiqqoru7u6orKws5LgAyTJEPgKTjXwEGNlY5EhBz4D39fXFrl27or6+fugOSkujvr4+2tvbT+s+3nvvvXj//ffjwgsvLOykABOYfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/btO637uOeee2LWrFnDQviP9fb2Rm9v7+DXPT09hRwTIDn5CJCffAQYkvRd0NevXx9btmyJ559/PioqKkZc19LSElVVVYO3mpqahKcESE8+AuQnH4FiUlABnzZtWpSVlUVXV9ew611dXTFjxoyT7n344Ydj/fr18eMf/ziuvPLKk65dvXp1dHd3D94OHjxYyDEBkpOPAPnJR4AhBRXw8vLymD9/frS1tQ1eGxgYiLa2tqirqxtx30MPPRQPPvhgtLa2xoIFC075OLlcLiorK4fdACYy+QiQn3wEGFLQ34BHRDQ1NcWyZctiwYIFsXDhwtiwYUMcPXo0li9fHhERS5cujdmzZ0dLS0tERPzzP/9zrF27Np555pmYM2dOdHZ2RkTERz7ykfjIRz5yFkcBGF/yESA/+QhwXMEFvLGxMQ4dOhRr166Nzs7OmDdvXrS2tg6+scaBAweitHToifVvf/vb0dfXF3/zN38z7H6am5vja1/72pmdHmACkY8A+clHgOMK/hzw8eBzHIEzUcwZUsyzAWOvmDOkmGcD0hj3zwEHAAAARkcBBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhgVAV848aNMWfOnKioqIja2trYuXPnSdf/4Ac/iMsuuywqKiriiiuuiO3bt4/qsAATnXwEyE8+AoyigG/dujWampqiubk5du/eHXPnzo2GhoZ455138q5/5ZVX4uabb45bb7019uzZE4sXL47FixfHL37xizM+PMBEIh8B8pOPAMeVZFmWFbKhtrY2rr766njsscciImJgYCBqamrirrvuilWrVp2wvrGxMY4ePRo/+tGPBq/95V/+ZcybNy82bdp0Wo/Z09MTVVVV0d3dHZWVlYUcFyBZhshHYLKRjwAjG4scmVLI4r6+vti1a1esXr168FppaWnU19dHe3t73j3t7e3R1NQ07FpDQ0O88MILIz5Ob29v9Pb2Dn7d3d0dEcf/AwAU6oPsKPD3jQWRj8BkJB8BRjYWGVlQAT98+HD09/dHdXX1sOvV1dWxb9++vHs6Ozvzru/s7BzxcVpaWuKBBx444XpNTU0hxwUY5n/+53+iqqpqTO5bPgKTmXwEGNnZzMiCCngqq1evHvZbz3fffTc++tGPxoEDB8bsH4fx0NPTEzU1NXHw4MGie2mU2SanYp2tu7s7LrroorjwwgvH+yhn7MOSjxHF+/NYrHNFmG0yko+TU7H+PEYU72zFOldEcc82FhlZUAGfNm1alJWVRVdX17DrXV1dMWPGjLx7ZsyYUdD6iIhcLhe5XO6E61VVVUX3TY2IqKysLMq5Isw2WRXrbKWlY/fJi/Jx7BTrz2OxzhVhtslIPk5OxfrzGFG8sxXrXBHFPdvZzMiC7qm8vDzmz58fbW1tg9cGBgaira0t6urq8u6pq6sbtj4i4qWXXhpxPcBkJB8B8pOPAEMKfgl6U1NTLFu2LBYsWBALFy6MDRs2xNGjR2P58uUREbF06dKYPXt2tLS0RETE3XffHddff3088sgjcdNNN8WWLVvi5z//eTzxxBNndxKAcSYfAfKTjwDHFVzAGxsb49ChQ7F27dro7OyMefPmRWtr6+AbZRw4cGDYU/TXXHNNPPPMM3HffffFvffeG3/xF38RL7zwQlx++eWn/Zi5XC6am5vzvqxoMivWuSLMNlkV62yp5pKPZ1exzlasc0WYbTKSj5OT2SafYp0rwmyFKvhzwAEAAIDCjd07bgAAAACDFHAAAABIQAEHAACABBRwAAAASGDCFPCNGzfGnDlzoqKiImpra2Pnzp0nXf+DH/wgLrvssqioqIgrrrgitm/fnuikhSlkrs2bN8d1110XU6dOjalTp0Z9ff0p/zuMp0K/Zx/YsmVLlJSUxOLFi8f2gGeg0NnefffdWLFiRcycOTNyuVxceumlE/JnstC5NmzYEB//+Mfj3HPPjZqamli5cmX8/ve/T3Ta0/fTn/40Fi1aFLNmzYqSkpJ44YUXTrlnx44d8elPfzpyuVx87GMfi6effnrMzzlaxZqPEcWbkfJxyGTJx4jizEj5OJx8nBiKNSPl4xD5eBLZBLBly5asvLw8e+qpp7L/+q//ym6//fbsggsuyLq6uvKu/9nPfpaVlZVlDz30UPbaa69l9913X3bOOedkr776auKTn1yhc91yyy3Zxo0bsz179mR79+7N/u7v/i6rqqrK/vu//zvxyU+t0Nk+8NZbb2WzZ8/Orrvuuuyv//qv0xy2QIXO1tvbmy1YsCC78cYbs5dffjl76623sh07dmQdHR2JT35yhc71ve99L8vlctn3vve97K233spefPHFbObMmdnKlSsTn/zUtm/fnq1ZsyZ77rnnsojInn/++ZOu379/f3beeedlTU1N2WuvvZZ961vfysrKyrLW1tY0By5AseZjlhVvRsrHIZMlH7OseDNSPg6RjxNDsWakfBwiH09uQhTwhQsXZitWrBj8ur+/P5s1a1bW0tKSd/0XvvCF7Kabbhp2rba2Nvv7v//7MT1noQqd648dO3YsO//887Pvfve7Y3XEURvNbMeOHcuuueaa7Dvf+U62bNmyCRmeWVb4bN/+9reziy++OOvr60t1xFEpdK4VK1Zkn/3sZ4dda2pqyq699toxPeeZOp0A/epXv5p96lOfGnatsbExa2hoGMOTjU6x5mOWFW9GyschkyUfs+zDkZHyUT5OBMWakfJxiHw8uXF/CXpfX1/s2rUr6uvrB6+VlpZGfX19tLe3593T3t4+bH1ERENDw4jrx8No5vpj7733Xrz//vtx4YUXjtUxR2W0s33961+P6dOnx6233primKMymtl++MMfRl1dXaxYsSKqq6vj8ssvj3Xr1kV/f3+qY5/SaOa65pprYteuXYMvMdq/f39s3749brzxxiRnHkuTIUMiijcfI4o3I+XjcJMhHyNk5B8q5gwp5tn+2ETMx4jizUj5OJx8PLkpZ/NQo3H48OHo7++P6urqYderq6tj3759efd0dnbmXd/Z2Tlm5yzUaOb6Y/fcc0/MmjXrhG/0eBvNbC+//HI8+eST0dHRkeCEozea2fbv3x//8R//EV/84hdj+/bt8eabb8aXv/zleP/996O5uTnFsU9pNHPdcsstcfjw4fjMZz4TWZbFsWPH4s4774x77703xZHH1EgZ0tPTE7/73e/i3HPPHaeTDVes+RhRvBkpH4ebDPkYISP/kHwcf8WajxHFm5HycTj5eHLj/gw4+a1fvz62bNkSzz//fFRUVIz3cc7IkSNHYsmSJbF58+aYNm3aeB/nrBsYGIjp06fHE088EfPnz4/GxsZYs2ZNbNq0abyPdkZ27NgR69ati8cffzx2794dzz33XGzbti0efPDB8T4aFE1GysfJS0YyURVLPkYUd0bKxw+vcX8GfNq0aVFWVhZdXV3Drnd1dcWMGTPy7pkxY0ZB68fDaOb6wMMPPxzr16+Pf//3f48rr7xyLI85KoXO9stf/jLefvvtWLRo0eC1gYGBiIiYMmVKvP7663HJJZeM7aFP02i+bzNnzoxzzjknysrKBq994hOfiM7Ozujr64vy8vIxPfPpGM1c999/fyxZsiRuu+22iIi44oor4ujRo3HHHXfEmjVrorR08v7+bqQMqaysnDDP7kQUbz5GFG9GysfhJkM+RsjIPyQfx1+x5mNE8WakfBxOPp7cuE9fXl4e8+fPj7a2tsFrAwMD0dbWFnV1dXn31NXVDVsfEfHSSy+NuH48jGauiIiHHnooHnzwwWhtbY0FCxakOGrBCp3tsssui1dffTU6OjoGb5///OfjhhtuiI6OjqipqUl5/JMazfft2muvjTfffHPwH4SIiDfeeCNmzpw5YcJzNHO99957JwTkB/9IHH+vislrMmRIRPHmY0TxZqR8HG4y5GOEjPxDxZwhxTxbxMTPx4jizUj5OJx8PIWC3rJtjGzZsiXL5XLZ008/nb322mvZHXfckV1wwQVZZ2dnlmVZtmTJkmzVqlWD63/2s59lU6ZMyR5++OFs7969WXNz84T8GIlC51q/fn1WXl6ePfvss9lvfvObwduRI0fGa4QRFTrbH5uo72CZZYXPduDAgez888/P/uEf/iF7/fXXsx/96EfZ9OnTs2984xvjNUJehc7V3NycnX/++dm//du/Zfv3789+/OMfZ5dcckn2hS98YbxGGNGRI0eyPXv2ZHv27MkiInv00UezPXv2ZL/61a+yLMuyVatWZUuWLBlc/8HHSPzTP/1Ttnfv3mzjxo0T+mN2ijEfs6x4M1I+Tr58zLLizUj5KB8nmmLNSPkoH0/XhCjgWZZl3/rWt7KLLrooKy8vzxYuXJj953/+5+D/dv3112fLli0btv773/9+dumll2bl5eXZpz71qWzbtm2JT3x6Cpnrox/9aBYRJ9yam5vTH/w0FPo9+0MTNTw/UOhsr7zySlZbW5vlcrns4osvzr75zW9mx44dS3zqUytkrvfffz/72te+ll1yySVZRUVFVlNTk335y1/O/vd//zf9wU/hJz/5Sd7/73wwz7Jly7Lrr7/+hD3z5s3LysvLs4svvjj713/91+TnPl3Fmo9ZVrwZKR+HTJZ8zLLizEj5uGzYevk4MRRrRsrH4+TjyZVk2SR+HQAAAABMEuP+N+AAAADwYaCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAv8PErIwn8QKNHkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "T_lists = [0.1, 0.01, 0.001]\n",
    "tot = gate_h[0][0].shape[0] *  gate_h[0][0].shape[1] *  gate_h[0][0].shape[2] \n",
    "fig, axes = plt.subplots(1, len(T_lists), figsize=(12, 4))\n",
    "for n, T in enumerate(T_lists):\n",
    "    gate_act_rate = []\n",
    "    for i in range(n_layer):\n",
    "        after_act = F.silu(gate_h[i][0]).detach()\n",
    "        gate_act_rate.append(torch.sum(torch.abs(after_act) > T) / tot)\n",
    "    axes[n].bar([_ for _ in range(n_layer)], gate_act_rate)\n",
    "    print(np.mean(gate_act_rate))\n",
    "    print(min(gate_act_rate))\n",
    "    print(max(gate_act_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对激活值进行归一化（softmax, 或者l1 normalization）之后，有多少的贡献度会大于给定的阈值T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_softmax_rate = []\n",
    "norm = 'softmax'\n",
    "# norm = 'l1'\n",
    "T = 0.001\n",
    "tot = gate_h[0][0].shape[0] *  gate_h[0][0].shape[1] *  gate_h[0][0].shape[2]\n",
    "for i in range(n_layer):\n",
    "    abs_score = torch.abs(F.silu(gate_h[i][0]))\n",
    "    norm_gate_h = F.softmax(abs_score, dim=-1) if norm == \"softmax\" else F.normalize(abs_score, dim=-1, p=1)\n",
    "    gate_softmax_rate.append(\n",
    "        torch.sum(norm_gate_h > T) / tot\n",
    "    )\n",
    "plt.bar([_ for _ in range(n_layer)], gate_softmax_rate)\n",
    "print(np.mean(gate_softmax_rate))\n",
    "print(min(gate_softmax_rate))\n",
    "print(max(gate_softmax_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 给定一个阈值T（比如说90%）,最少选取多少neuron使得这些neuron的贡献度大于这个阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'l1'\n",
    "T = 0.8\n",
    "cumsum_rate = []\n",
    "for i in range(n_layer):\n",
    "    selected_score = torch.abs(F.silu(gate_h[i][0]))  # [1, seq_len, neuron_num]\n",
    "    normed_selected_score = F.softmax(selected_score, dim=-1) if norm == 'softmax' else F.normalize(selected_score, dim=-1, p=1)\n",
    "    sorted_norm_values, _ = torch.sort(normed_selected_score, dim=-1, descending=True)\n",
    "    cumsum_sorted_norm_values = torch.cumsum(sorted_norm_values, dim=-1)\n",
    "    cumsum_rate.append(torch.sum(cumsum_sorted_norm_values < T) / tot)\n",
    "plt.bar([_ for _ in range(n_layer)], cumsum_rate)\n",
    "print(np.mean(cumsum_rate))\n",
    "print(min(cumsum_rate))\n",
    "print(max(cumsum_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于intermediate_abs进行分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 每一层有多少激活值的绝对值大于某一个阈值T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T= 0.01\n",
    "inter_abs_rate = []\n",
    "tot = down_h[0][0].shape[0] *  down_h[0][0].shape[1] *  down_h[0][0].shape[2] \n",
    "for i in range(n_layer):\n",
    "    score = torch.abs(down_h[i][0]).detach()\n",
    "    inter_abs_rate.append(torch.sum(score > T) / tot)\n",
    "plt.bar([_ for _ in range(n_layer)], inter_abs_rate)\n",
    "print(np.mean(inter_abs_rate))\n",
    "print(min(inter_abs_rate))\n",
    "print(max(inter_abs_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对激活值进行归一化（softmax, 或者l1 normalization）之后，有多少的贡献度会大于给定的阈值T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_abs_softmax_rate = []\n",
    "norm = 'softmax'\n",
    "# norm = 'l1'\n",
    "T = 0.001\n",
    "for i in range(n_layer):\n",
    "    abs_score = torch.abs(down_h[i][0])\n",
    "    norm_score = F.softmax(abs_score, dim=-1) if norm == \"softmax\" else F.normalize(abs_score, dim=-1, p=1)\n",
    "    inter_abs_softmax_rate.append(\n",
    "        torch.sum(norm_score > T) / tot\n",
    "    )\n",
    "plt.bar([_ for _ in range(n_layer)], inter_abs_softmax_rate)\n",
    "print(np.mean(inter_abs_softmax_rate))\n",
    "print(min(inter_abs_softmax_rate))\n",
    "print(max(inter_abs_softmax_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 给定一个阈值T（比如说90%）,最少选取多少neuron使得这些neuron的贡献度大于这个阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'l1'\n",
    "T = 0.8\n",
    "cumsum_rate = []\n",
    "for i in range(n_layer):\n",
    "    selected_score = torch.abs(down_h[i][0])  # [1, seq_len, neuron_num]\n",
    "    normed_selected_score = F.softmax(selected_score, dim=-1) if norm == 'softmax' else F.normalize(selected_score, dim=-1, p=1)\n",
    "    sorted_norm_values, _ = torch.sort(normed_selected_score, dim=-1, descending=True)\n",
    "    cumsum_sorted_norm_values = torch.cumsum(sorted_norm_values, dim=-1)\n",
    "    cumsum_rate.append(torch.sum(cumsum_sorted_norm_values < T) / tot)\n",
    "plt.bar([_ for _ in range(n_layer)], cumsum_rate)\n",
    "print(np.mean(cumsum_rate))\n",
    "print(min(cumsum_rate))\n",
    "print(max(cumsum_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
